---
title: linear_model_analysis 
output: 
  html_document: 
    highlight: pygments
    theme: spacelab
    toc: yes
---
# package
```{r message=F, warning=}
rm(list = ls())
knitr::opts_chunk$set(eval = F, cache = T, message = F, warning=F)
library(dplyr)
library(magrittr)
library(ggplot2)
library("gridExtra")
library("cowplot")
library(car)
library(FactoMineR)
library(factoextra)
library(ade4)
library(vegan)
library(MASS)
library(ellipse)
library(smatr)
library(TeachingDemos)
library(kableExtra)

source("https://raw.githubusercontent.com/talgalili/R-code-snippets/master/boxplot.with.outlier.label.r") # Load the function for outliers label

options(knitr.table.format = "html")

path <- "C:\\Users\\emduc\\Desktop\\Drive\\symphostage\\"
# path <- "./data/" # To be used on sylvain local machine
```

# I- data

```{r}

environment_trait<- read.csv(file.path(path, "environment_trait.csv"),header = T, dec = ".", sep=",") 

data_standar <- read.csv(file.path(path, "data_standar.csv"),header = T, dec = ".", sep=",") 

# sympho_gis <- environment_trait %>% 
#   dplyr::select(n_parcelle, n_carre, n_arbre, Xutm, Yutm)
# write.csv(sympho_gis, file="C:\\Users\\emduc\\Desktop\\sympho_gis.csv")
```
In the following text, the terms descriptors and varaible will be used interchangeably. These refereing to the attributes (not in the functional way), or character used to describe or compoare the object of the study.


## 1 Symphonia Height allometry 

In Frédérique Collinet thesis (1997), there is an allometry equation espacially design for Symphonia globulifera (on 219 individual) by the way in need to check ifin this study they made the difference between morphotypes in the individual selection or not. 

The final equation is H = a DBH^b with a  : the liberation point of the tree and b : "mean adult tree" which is an virtual tree defining the species stand of which diameter is checked by : dg= sqrt(4gb/ pi ) and gb is the mean basal area of the present category (cf. develoment category based on H = 100d relation by Oldeman (thesis p27) gb= 1/N somme(gi) where gi is basal area of the focal tree in the present category and N is the total number of tree in the present category.

As we have diameter data for our trees, we can apply this allometry and used the result as an additionnal descriptor. 


```{r}
# environment_trait <- environment_trait %>% 
#   mutate( Height = 5.34*(environment_trait$diameter)^0.471)
```

Also as we know the coefficient b, we can add an dummy variable to category in young or adult tree which would be a first clue to deal with the ontogenic effect. 

There is no detailled value of liberation height (Hl in meter), mean adult height (Hg in meter) and mean adult diameter (Dg in cenitmeter) for Symphonia globulifera available in the thesis. So I extract some value with a graphical lecture that is for sure unaccurate but it is all I have. 

Hl = 23.75 ; Hg = 28.16 ; Dg = 34.37



So for every tree that are going to be under this value I will consider them as young individual and the other one like adulte with a dummy variable.

```{r}
# environment_trait <- environment_trait %>%  
#   mutate (adulte = ifelse((diameter < 34.37 | Height < 28.16), 0,1))
```



## 2- spotting outliers 


```{r v, eval=FALSE, include=FALSE}

environment_trait <- environment_trait %>% 
  mutate(ID= as.factor(paste(n_parcelle, n_carre, n_arbre, sep="_")))

outliers_name <- environment_trait$ID
```
### a) SLA
```{r SLA outliers, echo=FALSE}
boxplot.with.outlier.label(environment_trait$SLA,outliers_name, main = "SLA outliers ")%$% 
data.frame(ID = outlier_df$label_name)  %>%  inner_join((environment_trait %>% dplyr::select(ID, SLA)), by = "ID") 
```
So there is four outliersaccording to boxplot analysis, 11-1-742 and 11-4-983 have really abberrant value whereas 13-2-73 and 15-1-198 can be consider are maximum range value for SLA. So here we only delete aberrant value. 

### b)LMDC
```{r LDMC outliers, echo=FALSE}
boxplot.with.outlier.label(environment_trait$LDMC,outliers_name,main = "LDMC outliers ") %$% 
data.frame(ID =outlier_df$label_name) %>%  inner_join((environment_trait %>% dplyr::select(ID, LDMC)), by = "ID") 
```
So there are 7 value that are consider as outliers, only two individuals are really far from de global distribution 2_3_236 and 1-2-387, so we decide to delete those ones.

### c) LT_mean

```{r LT outliers, echo=FALSE}
boxplot.with.outlier.label(environment_trait$LT_mean,outliers_name,main = "Leaf thickness outliers ")
```
For Lt_mean there is no outliers ! 

### d) Chloro content
```{r chloro outliers, echo=FALSE}
boxplot.with.outlier.label(environment_trait$Chloro_content,outliers_name, main = "Chlorophyll content outliers ")%$% 
data.frame(ID= outlier_df$label_name) %>%  inner_join((environment_trait %>% dplyr::select(ID, Chloro_content)), by = "ID")
```

there is one outlier so we removed it (justification ?)

### e)  Area 

```{r LA outliers, echo=FALSE}
boxplot.with.outlier.label(environment_trait$Area_exclude,outliers_name, main = "Leaf area outliers ")%$% 
data.frame(ID = outlier_df$label_name)%>%  inner_join((environment_trait %>% dplyr::select(ID, Area_exclude)), by = "ID") 
```

Here there are 20 individuals which are consider as Area outlier.Some individuals have extremly big leaves, so it is not an measure error. This leaf area variability should be kept in the data set it isa reality of our sampling.

### deleted outliers 

```{r}
environment_trait$SLA[which(environment_trait$ID == "11_1_742"| environment_trait$ID == "11_4_983")] <- NA

environment_trait$LMDC[which(environment_trait$ID == "2_3_236" |environment_trait$ID == "1_2_387")] <- NA

environment_trait$Chloro_content[which(environment_trait$ID == "15_1_637")] <- NA

```


## data distribution 


```{r trait distribution , eval=FALSE, include=FALSE}

SLA <- ggplot(environment_trait, aes(SLA))+
  geom_histogram()
LDMC <- ggplot(environment_trait, aes(LMDC))+
  geom_histogram()
LT <- ggplot(environment_trait, aes(LT_mean))+
  geom_histogram()
Chloro <- ggplot(environment_trait, aes(Chloro_content))+
  geom_histogram()
Area <- ggplot(environment_trait, aes(Area_exclude))+
  geom_histogram()
 Area.log <- ggplot(environment_trait, aes(log10(Area_exclude)))+
  geom_histogram()

plot_grid(SLA, LDMC, LT, Chloro, Area ,Area.log , ncol = 2, nrow = 3)
```


```{r}
# summary(environment_trait %>%  dplyr::select(SLA, LMDC, LT_mean, Area_exclude, Chloro_content)) %>% 
# kable() %>%  kable_styling(bootstrap_options = "condensed",  full_width = F)
```

## 3- standardisation 

all variable have been reduce and centered by z-score method to have demensionless variables.
```{r trait standar}
trait_standar <- environment_trait %>%
  dplyr::select(n_parcelle, n_carre, n_arbre,LT_mean, Chloro_content, LMDC, SLA, Area_exclude) 

trait_standar[,4:8] <- as.data.frame(scale(as.matrix(trait_standar[,4:8]), center = TRUE, scale = TRUE))
```
  

```{r standar envi }
environment_standar <- environment_trait %>% 
  dplyr::select(n_parcelle, n_carre, n_arbre, Dawkins, lBAL,wetness,   d_creek,dem,slope, d_gap, alt_creek, TRI, curvature) %>% 
  mutate(alt_creek = as.numeric(alt_creek), Dawkins = as.factor(Dawkins))  

environment_standar[,5:13] <- as.data.frame(scale(as.matrix(environment_standar[,5:13]),scale = TRUE, center = TRUE)) 

```


## 4- descriptors selection

```{r}
acp_envi <- PCA(environment_standar[,5:13], graph =  FALSE)


fviz_pca_var (acp_envi , axes = c(1, 2), label ="var", scaling =2)
fviz_pca_var (acp_envi , axes = c(2, 3), label ="var", scaling =2)
fviz_screeplot(acp_envi, ncp=10)
```

```{r}
environment_standar <- environment_standar %>% 
  dplyr::select(-slope, -d_creek, -dem, -curvature, -TRI)

acp_envi <- PCA(environment_standar[,5:8], graph =  FALSE)
fviz_pca_var (acp_envi , axes = c(1, 2), label ="var", scaling =2)

```


### c) checking colinnearity 

function to print coeficient of correlation on a pairs plot with an significant test. Here we choose to use Spearman correlation because every environmental variable does not answer to the normal distribution assumption made by the pearson coefficient of correlation. 

```{r eval=FALSE, include=FALSE}
panel.cor <- function(x, y, digits=2, prefix="", cex.cor) {
  usr <- par("usr")
  on.exit(par(usr))
  par(usr = c(0, 1, 0, 1))
  r <- abs(cor(x, y, use = "complete.obs", method = "spearman"))
  txt <- format(c(r, 0.123456789), digits = digits)[1]
  txt <- paste(prefix, txt, sep = "")
  if (missing(cex.cor)) cex <- 0.7 / strwidth(txt)

  test <- cor.test(x, y)
  # borrowed from printCoefmat
  Signif <- symnum(
    test$p.value, corr = FALSE, na = FALSE,
    cutpoints = c(0, 0.05, 0.1, 1),
    symbols = c("*", ".", " ")
  )

  text(0.5, 0.5, txt, cex = cex * r)
  text(.8, .8, Signif, cex = cex, col = 2)
}
```


```{r data standar}

data_standar <- full_join(environment_standar, trait_standar, by = c("n_parcelle", "n_carre", "n_arbre")) %>% 
  mutate(ID = paste (n_parcelle, n_carre, n_arbre, sep="_"))

data_standar$SLA[which(data_standar$ID == "11_1_742"| data_standar$ID == "11_4_983")] <- NA

data_standar$LMDC[which(data_standar$ID == "2_3_236" |data_standar$ID == "1_2_387")] <- NA

data_standar$Chloro_content[which(data_standar$ID == "15_1_637")] <- NA

#data_standar %>%  filter( ID == "11_4_983" |ID == "11_1_742" | ID == "2_3_236" |ID == "1_2_387" |ID == "15_1_637" )
                          
           
#write.csv(data_standar, file="C:\\Users\\emduc\\Desktop\\Drive\\symphostage\\data_standar.csv")
```



 Scaling 1 = distance biplot: the eigenvectors are scaled to unit length. (1)
Distances among objects in the biplot are approximations of their
Euclidean distances in multidimensional space. (2) The angles among
descriptor vectors are meaningless.

Scaling 2 = correlation biplot: each eigenvector is scaled to the square root of
its eigenvalue. (1) Distances among objects in the biplot are not approximations
of their Euclidean distances in multidimensional space. (2) The angles
between descriptors in the biplot reflect their correlations.
–– In both cases, projecting an object at right angle on a descriptor approximates the position of the object along that descriptor.
–– Bottom line: if the main interest of the analysis is to interpret the relationships among objects, choose scaling 1. If the main interest focuses on the relationships among descriptors, choose scaling 2.

```{r}
envi_soil <-  environment_trait %>%  filter(!is.na(Carbonmean)) %>% 
  dplyr::select(n_parcelle, n_carre, n_arbre, Dawkins, Carbonmean, Phosphorme ,wetness,lBAL, d_gap, alt_creek ,SLA , LT_mean, Chloro_content, Area_exclude, LMDC) %>% 
  mutate(alt_creek = as.numeric(alt_creek))

envi_soil[,5:15] <- as.data.frame(scale(as.matrix(envi_soil[,5:15]),scale = TRUE, center = TRUE)) 

#write.csv(envi_soil, file="C:\\Users\\emduc\\Desktop\\Drive\\symphostage\\envi_soil.csv")

acp_soil <- PCA(envi_soil[,5:10], graph =  FALSE)
fviz_pca_var (acp_soil , axes = c(1, 2), label ="var", scaling =2)
fviz_screeplot(acp_soil, ncp=10)

```


```{r}

soil_data <-  environment_trait %>%  filter(!is.na(Carbonmean)) %>% 
  dplyr::select(Carbonmean, Phosphorme ,wetness, d_gap, alt_creek , TRI, d_creek, curvature, slope, dem, aspect) 



soil_data[,3:11] <- as.data.frame(scale(as.matrix(soil_data[,3:11]),scale = TRUE, center = TRUE)) 

# C_model<- lm(soil_data$Carbonmean~., data = soil_data[,3:11])
# step(C_model, direction = "both")

lm(formula = soil_data$Carbonmean ~ alt_creek + d_creek + curvature + 
    dem, data = soil_data[, 3:11]) %>% summary


```

```{r}
P_model<- lm(log(soil_data$Phosphorme)~., data = soil_data[,3:11])
step(P_model, direction = "both")

lm(formula = log(soil_data$Phosphorme) ~ alt_creek + TRI + d_creek, 
    data = soil_data[, 3:11]) %>% summary


```

### trait 


```{r}
trait.pca <- PCA(trait_standar[,4:8], graph = F)
fviz_pca_biplot(trait.pca , axes = c(1, 2), label ="var", scaling =2, col.var="contrib", col.ind="grey")
fviz_screeplot(trait.pca, ncp=10)
```



## both 
```{r }

pairs(cbind(environment_standar[,5:11], trait_standar[,4:8]), lower.panel = panel.smooth, upper.panel = panel.cor)
```






## chloro content

```{r chloro model 1 }
chloro_model <- lm(Chloro_content~ wetness + d_creek + diameter + d_gap + lBAL + aspect+  diameter:lBAL + diameter:d_gap + wetness:diameter + d_creek:diameter, data = data_standar[, 4:9 & 12])

summary(chloro_model)
```
```{r chloro model 2}
chloro_model <- lm(formula = Chloro_content ~ wetness +  diameter +
    diameter:lBAL + d_creek:diameter, 
    data = data_standar[, 4:9 & 13])

summary(chloro_model)
```
d_gap does not have a significant coefficient anymore.

This is almost the same than LDMC, it is not so suprinsing because both are correlated (0.51, on pair panel)

#rda 

## data checking 


```{r , message = FALSE ,eval= F}
library(faraway)
sort(faraway::vif(environment_standar[,4:10]) )
```

Borcard et al. 2011: 175 argue that in the case of RDA, VIFs > 10 should be avoided, so here everything is right. 

As said in Legendre & Legendre 2011 RDA is a multivariate (meaning multiresponse) multiple linear regression followed by a PCA of the table of fitted values. It works as follows, on a matrix Y of centred response data and a matrix X of centred (or, more generally,standardized) explanatory variables.

As we previously standardized the matrix of Y we are going to only centered it.

```{r}
trait_center <- environment_trait %>%
  dplyr::select(n_parcelle, n_carre, n_arbre,LT_mean, Chloro_content, LMDC, SLA, Area_exclude) 

trait_center[,4:8] <- as.data.frame(scale(as.matrix(trait_center[,4:8]), center = TRUE, scale =  FALSE))
```


## analysis
In RDA, one can truly say that the axes explain or model (in the statistical sense)
the variation of the dependent matrix. Furthermore, a hypothesis (H0) of absence of
linear relationship between Y and X can be tested in RDA; this is not the case in
PCA


If lm part is not run before you need to remove n_parcelle, n_carre and n_arbre from trait_standar and environment_standar

```{r include=FALSE}
 trait_standar2 <- trait_standar %>% 
  dplyr::select(-n_parcelle, -n_carre, -n_arbre)
environment_standar2 <- environment_standar %>% 
  dplyr::select(-n_parcelle, -n_carre, -n_arbre)

rda_trait <- rda(trait_standar2~.,environment_standar2,scale = T, na.omit= T)
summary(rda_trait)

```

Now rda model validation 
```{r}
coef(rda_trait)
set.seed(111)
anova.cca(rda_trait, step=1000)
anova.cca(rda_trait, by="axis", step= 1000)
```

## plot 
```{r}
plot(rda_trait, scaling = 2, main = "Triplot RDA scaling 2 - wa scores")
var.sc <- scores(rda_trait, choices = 1:2, scaling = 2, display = "species")

arrows(0, 0, var.sc[, 1], var.sc[,2], length = 0, lty = 1, col = "red")
text(scores(rda_trait, display="species", choices=c(1), scaling=2),
     scores(rda_trait, display="species", choices=c(2), scaling=2, adj = c(-2,2)),
     labels=rownames(scores(rda_trait, display="species", choices=c(2), scaling=2)),
     col="red") 



plot(rda_trait, scaling = 1, main = "Triplot RDA scaling 1 - wa scores")
var.sc <- scores(rda_trait, choices = 1:2, scaling = 1, display = "species")

arrows(0, 0, var.sc[, 1], var.sc[,2], length = 0, lty = 1, col = "red")
text(scores(rda_trait, display="species", choices=c(1), scaling=1),
     scores(rda_trait, display="species", choices=c(2), scaling=1, adj = c(-2,2)),
     labels=rownames(scores(rda_trait, display="species", choices=c(2), scaling=1)),
     col="red") 
```


Scaling 1 – distance biplot: (1) Projecting an object at right angle on a response
variable or a quantitative explanatory variable approximates the position of
the object along that variable. (2) The angles between response and explanatory
variables in the biplot reflect their correlations (but not the angles among
response variables). (3) The relationship between the centroid of a qualitative
explanatory variable and a response variable (species) is found by projecting the
centroid at right angle on the species variable, as for individual objects, since we
are projecting the centroid of a group of objects. (4) Distances among centroids,
and between centroids and individual objects, approximate their Euclidean
distances.
• Scaling 2 – correlation biplot: (1) Projecting an object at right angle on a
response or a quantitative explanatory variable approximates the value of the
object along that variable. (2) The angles in the biplot between response and
explanatory variables, and between response variables themselves or explanatory
variables themselves, reflect their correlations. (3) The relationship
between the centroid of a qualitative explanatory variable and a response variable
(species) is found by projecting the centroid at right angle on the species variable (as for individual objects). (4) Distances among centroids, and between
centroids and individual objects, do not approximate their Euclidean
distances.



Ezekiel’s formula (Ezekiel 1930)for multivariate adjusted r-squared 

```{r}
RsquareAdj(rda_trait)$adj.r.squared
```

# varcomp 

```{r}
library(ape)
library(nlme)

varcomp_data <- read.csv(file.path(path, "varcomp_data.csv"),header = T, dec = ".", sep=",") %>% 
filter(SLA < 400) %>% 
filter(!(LMDC < 0.17 |LMDC > 0.55)) %>% 
 filter(! Chloro_content < 40.5)
```

## normality test 

```{r}
hist((varcomp_data$SLA))
hist((varcomp_data$LMDC))
hist((varcomp_data$Chloro_content))
hist((varcomp_data$LT_mean))
hist((varcomp_data$Area_exclude))
```

execpt for leaf area distribution that is right squewed , other distribution are not so far from "normal distribution shape"
```{r}
 shapiro.test((varcomp_data$SLA))
shapiro.test((varcomp_data$LMDC))
 shapiro.test((varcomp_data$Chloro_content))
shapiro.test((varcomp_data$LT_mean))
shapiro.test(log10(varcomp_data$Area_exclude))
```

Even if shapiro test do not confirm the normal distribution even after log or sqrt transformation, actual distribution are acceptable to continue parametric test as variance component analysis. 

```{r}
varcomp_data <- varcomp_data %>% 
  mutate( Area_exclude=log10(Area_exclude))
```

## standar deviation test / homoscedasticity test

Heteroscedasticity is much less of a problem when you have a balanced design (equal sample sizes in each group). Early results suggested that heteroscedasticity was not a problem at all with a balanced design (Glass et al. 1972), but later results found that large amounts of heteroscedasticity can inflate the false positive rate, even when the sample sizes are equal (Harwell et al. 1992)

Performs Bartlett's test of the null that the variances in each of the groups (samples) are the same.

Bartlett's test is not a particularly good one, because it is sensitive to departures from normality as well as heteroscedasticity; you shouldn't panic just because you have a significant Bartlett's test. It may be more helpful to use Bartlett's test to see what effect different transformations have on the heteroscedasticity; you can choose the transformation with the highest (least significant) P value for Bartlett's test.

The test has the null hypothesis that the variances are equal and the alterntive hypothesis that they are not equal.
```{r}
data_barlett <- varcomp_data  %>% dplyr::select(n_parcelle, n_carre, n_arbre, SLA, LMDC, LT_mean, Area_exclude, Chloro_content) %>%  mutate(ID = paste(n_parcelle, n_carre, n_arbre, sep="_")) %>% dplyr::select(-n_parcelle,-n_carre,-n_arbre)

data_barlett <-reshape::melt(data_barlett,  id=c("ID"))

bartlett.test(data_barlett$value, data_barlett$variable)


```

here p-value is significant so H0 is rejected , variances are not equal.
```{r}
# varcomp_data[,7:11] <- as.data.frame(scale(as.matrix(varcomp_data[,7:11]), center = TRUE, scale = TRUE))
# 
# mean <- rbind(mean(varcomp_data$SLA), mean(varcomp_data$LMDC), mean(varcomp_data$LT_mean), mean(varcomp_data$Chloro_content), mean(varcomp_data$Area_exclude))
# 
# sd <- rbind(sd(varcomp_data$SLA), sd(varcomp_data$LMDC), sd(varcomp_data$LT_sd), sd(varcomp_data$Chloro_content), sd(varcomp_data$Area_exclude))
# 
# plot((mean), sd)
```



## varcomp analysis

```{r varcomp SLA}
varcomp.SLA<-varcomp(lme(SLA~1,
random=~1|n_parcelle/morphotype_field/n_arbre/n_feuille, data = varcomp_data ,na.action = na.omit),1)
```

```{r varcomp LMDC}
varcomp.LDMC<-varcomp(lme(LMDC~1,
random=~1|n_parcelle/morphotype_field/n_arbre/n_feuille, data = varcomp_data ,na.action = na.omit),1)
```

```{r varcomp LT}
varcomp.LT<-varcomp(lme(LT_mean~1,
random=~1|n_parcelle/morphotype_field/n_arbre/n_feuille, data = varcomp_data ,na.action = na.omit),1)
```


```{r varcomp Area}
varcomp.Area<-varcomp(lme(Area_exclude~1,
random=~1|n_parcelle/morphotype_field/n_arbre/n_feuille, data = varcomp_data ,na.action = na.omit),1)
```

```{r varcomp chloro}
varcomp.Chloro<-varcomp(lme(Chloro_content~1,
random=~1|n_parcelle/morphotype_field/n_arbre/n_feuille, data = varcomp_data ,na.action = na.omit),1)
```


```{r varcomp resu }

varcomp_resu <- as.data.frame(cbind(varcomp.Area, varcomp.LDMC, varcomp.LT, varcomp.SLA, varcomp.Chloro))

  varcomp_resu <- varcomp_resu %>% mutate( niveau = rownames(varcomp_resu)) %>% 
    dplyr::rename(Area = "varcomp.Area", LT="varcomp.LT", LDMC = "varcomp.LDMC", SLA = "varcomp.SLA", Chloro = "varcomp.Chloro")
  
varcomp_resu$niveau <- factor(varcomp_resu$niveau, levels = varcomp_resu$niveau)    

varcomp_resu <- reshape::melt(varcomp_resu,  id=c("niveau")) %>% 
  mutate(value1 = as.numeric(value*100)) %>% 
  mutate(niveau = as.factor(niveau))
  

```


```{r varcomp plot }
ggplot(varcomp_resu,aes(x = variable, y = value1, fill = niveau, order= niveau))+
  geom_bar(stat = "identity", position = "stack")+
  labs(title = "Variance component analysis", y = "fraction of the total variance explained
       by each scale (value*100) ", x= "functional trait")+
  scale_fill_brewer(palette="PiYG")
```



```{r varcomp PCA }

D.varcop <- as.data.frame(rbind(varcomp.Area, varcomp.LDMC, varcomp.LT, varcomp.SLA, varcomp.Chloro)) 

pca.varcomp <- PCA(D.varcop, graph= F)

fviz_pca_biplot(pca.varcomp , axes = c(1, 2), scaling =1, repel = TRUE)
```






### topo category





```{r varcomp sla 2}
varcomp.SLA2<-varcomp(lme(SLA~1,
random=~1|n_parcelle/topo/morphotype_field/n_arbre/n_feuille, data = varcomp_data ,na.action = na.omit),1)
```

```{r varcomp lmdc 2 }
varcomp.LDMC2<-varcomp(lme(LMDC~1,
random=~1|n_parcelle/topo/morphotype_field/n_arbre/n_feuille, data = varcomp_data ,na.action = na.omit),1)
```

```{r}
varcomp.LT2<-varcomp(lme(LT_mean~1,
random=~1|n_parcelle/topo/morphotype_field/n_arbre/n_feuille, data = varcomp_data ,na.action = na.omit),1)
```


```{r}
varcomp.Area2<-varcomp(lme(Area_exclude~1,
random=~1|n_parcelle/topo/morphotype_field/n_arbre/n_feuille, data = varcomp_data ,na.action = na.omit),1)
```

```{r}
varcomp.Chloro2<-varcomp(lme(Chloro_content~1,
random=~1|n_parcelle/topo/morphotype_field/n_arbre/n_feuille, data = varcomp_data ,na.action = na.omit),1)
```


```{r}

varcomp_resu2 <- as.data.frame(cbind(varcomp.Area2, varcomp.LDMC2, varcomp.LT2, varcomp.SLA2, varcomp.Chloro2))

  varcomp_resu2 <- varcomp_resu2 %>% mutate( niveau = rownames(varcomp_resu2)) %>% 
    dplyr::rename(Area = "varcomp.Area2", LT="varcomp.LT2", LDMC = "varcomp.LDMC2", SLA = "varcomp.SLA2", Chloro= "varcomp.Chloro2") 
  
varcomp_resu2$niveau <- factor(varcomp_resu2$niveau, levels = varcomp_resu2$niveau)    

varcomp_resu2 <- reshape::melt(varcomp_resu2,  id=c("niveau")) %>% 
  mutate(value1 = as.numeric(value*100)) %>%  
  mutate(niveau = as.factor(niveau))
  

```


```{r}
ggplot(varcomp_resu2,aes(x = variable, y = value1, fill = niveau, order= niveau))+
  geom_bar(stat = "identity", position = "stack")+
  labs(title = "Variance component analysis", y = "fraction of the total variance explained
       by each scale (value*100) ", x= "functional trait")+
  scale_fill_brewer(palette="PiYG")
```



```{r}
D.varcop2 <- as.data.frame(rbind(varcomp.Area2, varcomp.LDMC2, varcomp.LT2, varcomp.SLA2, varcomp.Chloro2)) 

pca.varcomp2 <- PCA(D.varcop2, graph= T)

fviz_pca_biplot(pca.varcomp2 , axes = c(1, 2), scaling =1, repel = TRUE)
```


```{r}
varcomp_resu %>%  filter(niveau == "n_arbre")

```

```{r}
varcomp_resu2 %>%  filter(niveau == "n_arbre")
```
